{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "settled-second",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from sklearn import datasets\n",
    "from sklearn import preprocessing\n",
    "from sklearn import model_selection\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "posted-antarctica",
   "metadata": {},
   "source": [
    "# Q1: Multi-Layer Perceptron for Classification Dataset:   \n",
    "You will use the UCI Optical Recognition of Handwritten Digits Dataset:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "systematic-adapter",
   "metadata": {},
   "source": [
    "#### 1. Implement the following function that creates a weight matrix and initializes it with small random real numbers. [4 pts]* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "japanese-devil",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initializeTheta(n1, n2):\n",
    "    theta1 = []\n",
    "    theta2 = []\n",
    "    theta  = []\n",
    "    \n",
    "    for i in range(n1):\n",
    "        theta1.append(np.random.uniform(-1, 1))\n",
    "\n",
    "    for i in range(n2):\n",
    "        theta2.append(np.random.uniform(-1, 1))\n",
    "    \n",
    "    theta.append(theta1)\n",
    "    theta.append(theta2)\n",
    "\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "strong-malpractice",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "r = initializeTheta(5, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "tired-earthquake",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[-0.3284531472033909,\n",
       "  -0.003042425115212355,\n",
       "  -0.1503540131103358,\n",
       "  -0.9256879152552444,\n",
       "  -0.3296369539341366],\n",
       " [-0.24588701491434728,\n",
       "  0.41207122642307503,\n",
       "  0.23762281267700636,\n",
       "  0.10532742172480725,\n",
       "  0.9204135846195691,\n",
       "  -0.8315324257000491,\n",
       "  -0.1614956365163449,\n",
       "  0.16417388919804887]]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cardiovascular-instrumentation",
   "metadata": {},
   "source": [
    "#### 2. Implement the logistic sigmoid activation function. [2 pts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "western-liberia",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic(z):\n",
    "    ret = []\n",
    "    for ele in z:\n",
    "        ret.append(1 / (1 + math.exp(-ele)))\n",
    "    \n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "american-advancement",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.4388361024521704,\n",
       " 0.6015844159495622,\n",
       " 0.559127745927232,\n",
       " 0.526307538901481,\n",
       " 0.7151263689225604,\n",
       " 0.30332114435255625,\n",
       " 0.45971361140782757,\n",
       " 0.5409515328122172]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic(r[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interstate-example",
   "metadata": {},
   "source": [
    "#### 3. Implement the ReLU (rectified linear unit) activation function. [3 pts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fitted-blame",
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(z):\n",
    "    ret = []\n",
    "    \n",
    "    for ele in z:\n",
    "        if ele>0:\n",
    "            ret.append(ele)\n",
    "        else:\n",
    "            ret.append(0)\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "identified-eligibility",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 0.41207122642307503,\n",
       " 0.23762281267700636,\n",
       " 0.10532742172480725,\n",
       " 0.9204135846195691,\n",
       " 0,\n",
       " 0,\n",
       " 0.16417388919804887]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relu(r[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "weekly-supply",
   "metadata": {},
   "source": [
    "#### 4. Implement the tanh (hyperbolic tangent) activation function. [3 pts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "entertaining-better",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tanh(z):\n",
    "    ret = []\n",
    "    \n",
    "    for ele in z:\n",
    "        ret.append((math.exp(ele)-math.exp(-ele))/(math.exp(ele)+math.exp(-ele)))\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "developed-earth",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.2410485185965348,\n",
       " 0.39022991932662243,\n",
       " 0.23324914340214184,\n",
       " 0.10493964631255583,\n",
       " 0.7260930118090146,\n",
       " -0.6812979879891466,\n",
       " -0.1601061496603105,\n",
       " 0.16271462330587555]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tanh(r[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beautiful-title",
   "metadata": {},
   "source": [
    "#### 5. Implement a MLPClassifier model class. It has a single hidden layer. It should have the following three methods. The model uses the backpropagation algorithm for learning the weights of the features/neurons. Note the that “fit” method should implement the Stochastic Gradient Descent algorithm for optimizing the weight update process. [40 pts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "significant-science",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class MLPClassifier():\n",
    "#     def __init__(self):\n",
    "#         pass\n",
    "\n",
    "    \n",
    "    \n",
    "#     def backpropagation():\n",
    "        \n",
    "        \n",
    "        \n",
    "#     # Stochastic Gradient Descent algorithm for optimizing the weight update process    \n",
    "#     def fit(self, X, Y, hidden_layer_neurons=2, activation= ‘logistic’, regularizer=None, alpha=0.0001,\n",
    "#             learning_rate=‘constant’, learning_rate_init=0.001, max_iter=1000, tol = 0.0001, verbose=False,\n",
    "#             early_stopping=False, validation_fraction=0.1, n_iter_no_change=10,**kwargs):\n",
    "        \n",
    "    \n",
    "#     def predict(self, X):\n",
    "        \n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "gentle-bosnia",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "incredible-continuity",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(64,), activation='relu', alpha=0.0001,\n",
    "                    solver='sgd', max_iter = 30, tol=1e-4, random_state=1, learning_rate = 'constant',\n",
    "                    learning_rate_init=0.001, early_stopping=True, validation_fraction=0.1, verbose=True, \n",
    "                    n_iter_no_change=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "downtown-purple",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "overhead-egypt",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "tested-russell",
   "metadata": {},
   "source": [
    "# Multi-Class Classification using MLPClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "surgical-victor",
   "metadata": {},
   "source": [
    "#### 6. Read the handwritten digits dataset using the sklearn.datasets.load_digits function for performing multi-class classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "better-detection",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = datasets.load_digits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "written-experiment",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DESCR', 'data', 'feature_names', 'frame', 'images', 'target', 'target_names']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "prerequisite-pasta",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['data', 'target', 'frame', 'feature_names', 'target_names', 'images', 'DESCR'])\n",
      "['pixel_0_0', 'pixel_0_1', 'pixel_0_2', 'pixel_0_3', 'pixel_0_4', 'pixel_0_5', 'pixel_0_6', 'pixel_0_7', 'pixel_1_0', 'pixel_1_1', 'pixel_1_2', 'pixel_1_3', 'pixel_1_4', 'pixel_1_5', 'pixel_1_6', 'pixel_1_7', 'pixel_2_0', 'pixel_2_1', 'pixel_2_2', 'pixel_2_3', 'pixel_2_4', 'pixel_2_5', 'pixel_2_6', 'pixel_2_7', 'pixel_3_0', 'pixel_3_1', 'pixel_3_2', 'pixel_3_3', 'pixel_3_4', 'pixel_3_5', 'pixel_3_6', 'pixel_3_7', 'pixel_4_0', 'pixel_4_1', 'pixel_4_2', 'pixel_4_3', 'pixel_4_4', 'pixel_4_5', 'pixel_4_6', 'pixel_4_7', 'pixel_5_0', 'pixel_5_1', 'pixel_5_2', 'pixel_5_3', 'pixel_5_4', 'pixel_5_5', 'pixel_5_6', 'pixel_5_7', 'pixel_6_0', 'pixel_6_1', 'pixel_6_2', 'pixel_6_3', 'pixel_6_4', 'pixel_6_5', 'pixel_6_6', 'pixel_6_7', 'pixel_7_0', 'pixel_7_1', 'pixel_7_2', 'pixel_7_3', 'pixel_7_4', 'pixel_7_5', 'pixel_7_6', 'pixel_7_7']\n",
      "[0 1 2 3 4 5 6 7 8 9]\n",
      "(1797, 64)\n"
     ]
    }
   ],
   "source": [
    "print(data.keys())\n",
    "print(data.feature_names)\n",
    "print(data.target_names)\n",
    "print(data.data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "adolescent-medicare",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1797,)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "terminal-territory",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  5. 13.  9.  1.  0.  0.]\n",
      " [ 0.  0. 13. 15. 10. 15.  5.  0.]\n",
      " [ 0.  3. 15.  2.  0. 11.  8.  0.]\n",
      " [ 0.  4. 12.  0.  0.  8.  8.  0.]\n",
      " [ 0.  5.  8.  0.  0.  9.  8.  0.]\n",
      " [ 0.  4. 11.  0.  1. 12.  7.  0.]\n",
      " [ 0.  2. 14.  5. 10. 12.  0.  0.]\n",
      " [ 0.  0.  6. 13. 10.  0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "print(data.images[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "involved-diamond",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1797, 64)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "lonely-fundamental",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1797, 8, 8)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "great-xerox",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.gray() \n",
    "plt.matshow(data.images[0]) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "registered-conclusion",
   "metadata": {},
   "source": [
    "#### 7. Standardize the features. [1 pts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "taken-fault",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = preprocessing.StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "conditional-belle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  5. ...  0.  0.  0.]\n",
      " [ 0.  0.  0. ... 10.  0.  0.]\n",
      " [ 0.  0.  0. ... 16.  9.  0.]\n",
      " ...\n",
      " [ 0.  0.  1. ...  6.  0.  0.]\n",
      " [ 0.  0.  2. ... 12.  0.  0.]\n",
      " [ 0.  0. 10. ... 12.  1.  0.]]\n"
     ]
    }
   ],
   "source": [
    "print(data.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "palestinian-sector",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler()"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.fit(data.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "southern-anniversary",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00000000e+00 3.03839733e-01 5.20478575e+00 1.18358375e+01\n",
      " 1.18480801e+01 5.78185865e+00 1.36227045e+00 1.29660545e-01\n",
      " 5.56483027e-03 1.99387869e+00 1.03823038e+01 1.19794101e+01\n",
      " 1.02793545e+01 8.17584864e+00 1.84641068e+00 1.07957707e-01\n",
      " 2.78241514e-03 2.60155815e+00 9.90317195e+00 6.99276572e+00\n",
      " 7.09794101e+00 7.80634391e+00 1.78853645e+00 5.00834725e-02\n",
      " 1.11296605e-03 2.46967168e+00 9.09126322e+00 8.82136895e+00\n",
      " 9.92710072e+00 7.55147468e+00 2.31775181e+00 2.22593211e-03\n",
      " 0.00000000e+00 2.33945465e+00 7.66722315e+00 9.07178631e+00\n",
      " 1.03016138e+01 8.74401781e+00 2.90929327e+00 0.00000000e+00\n",
      " 8.90372844e-03 1.58375070e+00 6.88146912e+00 7.22815804e+00\n",
      " 7.67223150e+00 8.23650529e+00 3.45631608e+00 2.72676683e-02\n",
      " 7.23427935e-03 7.04507513e-01 7.50695604e+00 9.53923205e+00\n",
      " 9.41624930e+00 8.75848637e+00 3.72509738e+00 2.06455203e-01\n",
      " 5.56483027e-04 2.79354480e-01 5.55759599e+00 1.20890373e+01\n",
      " 1.18091263e+01 6.76405120e+00 2.06789093e+00 3.64496383e-01]\n",
      "[1.         0.90693964 4.75350317 4.24765948 4.28619491 5.66484088\n",
      " 3.32484969 1.03709417 0.09419533 3.19527098 5.41994694 3.97643575\n",
      " 4.78134964 6.05127561 3.58532293 0.82768465 0.06235094 3.57530605\n",
      " 5.68918332 5.80104695 6.17400993 6.19559718 3.25896254 0.43847543\n",
      " 0.03334258 3.14565685 6.19031469 5.88129939 6.15038083 5.87092136\n",
      " 3.68543009 0.04712725 1.         3.4794038  6.32292731 6.26664682\n",
      " 5.93183902 5.86901393 3.53629836 1.         0.14514503 2.98098645\n",
      " 6.53613529 6.43958504 6.25776954 5.69394162 4.32974601 0.30727036\n",
      " 0.20416633 1.74566694 5.64292531 5.22549314 5.30057302 6.02947606\n",
      " 4.91803706 0.98412698 0.02358333 0.9340418  5.1015993  4.37347662\n",
      " 4.93257433 5.89898069 4.08940957 1.85960409]\n"
     ]
    }
   ],
   "source": [
    "print(scaler.mean_)\n",
    "print(scaler.scale_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "supposed-karma",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaled = scaler.transform(data.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "resident-heart",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        , -0.33501649, -0.04308102, ..., -1.14664746,\n",
       "        -0.5056698 , -0.19600752],\n",
       "       [ 0.        , -0.33501649, -1.09493684, ...,  0.54856067,\n",
       "        -0.5056698 , -0.19600752],\n",
       "       [ 0.        , -0.33501649, -1.09493684, ...,  1.56568555,\n",
       "         1.6951369 , -0.19600752],\n",
       "       ...,\n",
       "       [ 0.        , -0.33501649, -0.88456568, ..., -0.12952258,\n",
       "        -0.5056698 , -0.19600752],\n",
       "       [ 0.        , -0.33501649, -0.67419451, ...,  0.8876023 ,\n",
       "        -0.5056698 , -0.19600752],\n",
       "       [ 0.        , -0.33501649,  1.00877481, ...,  0.8876023 ,\n",
       "        -0.26113572, -0.19600752]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adolescent-there",
   "metadata": {},
   "source": [
    "#### 8. Partition the data into train and test set. [2 pts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ancient-capitol",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data.target\n",
    "x = data.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "artistic-pleasure",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(x, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "center-transcript",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  3., ..., 13.,  4.,  0.],\n",
       "       [ 0.,  0.,  9., ...,  3.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  6.,  0.,  0.],\n",
       "       ...,\n",
       "       [ 0.,  0.,  9., ..., 16.,  2.,  0.],\n",
       "       [ 0.,  0.,  1., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  1., ...,  1.,  0.,  0.]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "nonprofit-discretion",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6, 0, 0, ..., 2, 7, 1])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "handled-louis",
   "metadata": {},
   "source": [
    "#### 9. You don’t need to report hyperparameter tuning. Note that unlike previous assignments, hyperparameter tuning is time-consuming for the MLP model. You may want to perform an educated tuning of the hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "precious-henry",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_layeys = [32, 64]\n",
    "activations = ['logistic','tanh','relu']\n",
    "alphas = [0.001, 0.0001]\n",
    "learning_rates = ['constant','invscaling']   # Only used when solver='sgd'\n",
    "learning_rate_inits = [0.001, 0.0001]  # Only used when solver=’sgd’ or ‘adam’\n",
    "n_iter_no_changes = [5,10]  # Only used when solver=’sgd’ or ‘adam’\n",
    "max_iters = [30, 50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "super-heaven",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for size in hidden_layeys:\n",
    "#     for act in activations:\n",
    "#         for al in alphas:\n",
    "#             for lr in learning_rates:\n",
    "#                 for ini in learning_rate_inits:\n",
    "#                     for chg in n_iter_no_changes:\n",
    "#                         for mx in max_iters:\n",
    "#                             mlp = MLPClassifier(hidden_layer_sizes=(size,), activation=act, alpha=al,\n",
    "#                                                 solver='sgd', max_iter = mx, tol=1e-4, random_state=1, learning_rate = lr,\n",
    "#                                                 learning_rate_init=ini, early_stopping=True, validation_fraction=0.1, verbose=True, \n",
    "#                                                 n_iter_no_change=chg)\n",
    "#                             mlp.fit(X_train,y_train)\n",
    "#                             pre = mlp.predict(X_test)\n",
    "#                             print(\"===========================================================================================\")\n",
    "#                             print(metrics.accuracy_score(y_test, pre))\n",
    "#                             print(size, act, al, lr, ini, chg, mx)\n",
    "#                             print(\"===========================================================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "voluntary-pillow",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 6.80391232\n",
      "Validation score: 0.250000\n",
      "Iteration 2, loss = 2.75832930\n",
      "Validation score: 0.618056\n",
      "Iteration 3, loss = 1.14069352\n",
      "Validation score: 0.666667\n",
      "Iteration 4, loss = 0.67182667\n",
      "Validation score: 0.763889\n",
      "Iteration 5, loss = 0.47859807\n",
      "Validation score: 0.791667\n",
      "Iteration 6, loss = 0.37558894\n",
      "Validation score: 0.833333\n",
      "Iteration 7, loss = 0.31664819\n",
      "Validation score: 0.847222\n",
      "Iteration 8, loss = 0.27807588\n",
      "Validation score: 0.868056\n",
      "Iteration 9, loss = 0.24893099\n",
      "Validation score: 0.868056\n",
      "Iteration 10, loss = 0.23044115\n",
      "Validation score: 0.868056\n",
      "Iteration 11, loss = 0.21331928\n",
      "Validation score: 0.875000\n",
      "Iteration 12, loss = 0.20025975\n",
      "Validation score: 0.875000\n",
      "Iteration 13, loss = 0.19101364\n",
      "Validation score: 0.875000\n",
      "Iteration 14, loss = 0.17818283\n",
      "Validation score: 0.881944\n",
      "Iteration 15, loss = 0.16953275\n",
      "Validation score: 0.881944\n",
      "Iteration 16, loss = 0.16060559\n",
      "Validation score: 0.881944\n",
      "Iteration 17, loss = 0.15496484\n",
      "Validation score: 0.881944\n",
      "Iteration 18, loss = 0.14729911\n",
      "Validation score: 0.888889\n",
      "Iteration 19, loss = 0.14317720\n",
      "Validation score: 0.888889\n",
      "Iteration 20, loss = 0.13708693\n",
      "Validation score: 0.909722\n",
      "Iteration 21, loss = 0.13138102\n",
      "Validation score: 0.895833\n",
      "Iteration 22, loss = 0.12667362\n",
      "Validation score: 0.895833\n",
      "Iteration 23, loss = 0.12255869\n",
      "Validation score: 0.895833\n",
      "Iteration 24, loss = 0.11892497\n",
      "Validation score: 0.895833\n",
      "Iteration 25, loss = 0.11481052\n",
      "Validation score: 0.902778\n",
      "Iteration 26, loss = 0.11079852\n",
      "Validation score: 0.895833\n",
      "Validation score did not improve more than tol=0.000100 for 5 consecutive epochs. Stopping.\n",
      "0.9472222222222222\n"
     ]
    }
   ],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(64,), activation='relu', alpha=0.0001,\n",
    "                    solver='sgd', max_iter = 30, tol=1e-4, random_state=1, learning_rate = 'constant',\n",
    "                    learning_rate_init=0.001, early_stopping=True, validation_fraction=0.1, verbose=True, \n",
    "                    n_iter_no_change=5)\n",
    "\n",
    "mlp.fit(X_train,y_train)\n",
    "pre = mlp.predict(X_test)\n",
    "print(metrics.accuracy_score(y_test, pre))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "appointed-rouge",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9472222222222222\n"
     ]
    }
   ],
   "source": [
    "print(mlp.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "similar-reference",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'activation': 'relu',\n",
       " 'alpha': 0.0001,\n",
       " 'batch_size': 'auto',\n",
       " 'beta_1': 0.9,\n",
       " 'beta_2': 0.999,\n",
       " 'early_stopping': True,\n",
       " 'epsilon': 1e-08,\n",
       " 'hidden_layer_sizes': (64,),\n",
       " 'learning_rate': 'constant',\n",
       " 'learning_rate_init': 0.001,\n",
       " 'max_fun': 15000,\n",
       " 'max_iter': 30,\n",
       " 'momentum': 0.9,\n",
       " 'n_iter_no_change': 5,\n",
       " 'nesterovs_momentum': True,\n",
       " 'power_t': 0.5,\n",
       " 'random_state': 1,\n",
       " 'shuffle': True,\n",
       " 'solver': 'sgd',\n",
       " 'tol': 0.0001,\n",
       " 'validation_fraction': 0.1,\n",
       " 'verbose': True,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sonic-least",
   "metadata": {},
   "source": [
    "the optimal values of the hyperparameters:  \n",
    "hidden_layer_neurons: 64  \n",
    "activation: relu  \n",
    "alpha: 0.0001   \n",
    "learning_rate: constant  \n",
    "learning_rate_init: 0.001  \n",
    "max_iter: 5  \n",
    "tol n_iter_no_change: 30  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "outstanding-function",
   "metadata": {},
   "source": [
    "#### 10. Your jupyter notebook should display the following items."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acquired-traveler",
   "metadata": {},
   "source": [
    "##### a) Epoch number, Training loss, validation loss, validation score, and step size (eta)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "broken-theta",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'activation': 'relu',\n",
       " 'alpha': 0.0001,\n",
       " 'batch_size': 'auto',\n",
       " 'beta_1': 0.9,\n",
       " 'beta_2': 0.999,\n",
       " 'early_stopping': True,\n",
       " 'epsilon': 1e-08,\n",
       " 'hidden_layer_sizes': (64,),\n",
       " 'learning_rate': 'constant',\n",
       " 'learning_rate_init': 0.001,\n",
       " 'max_fun': 15000,\n",
       " 'max_iter': 30,\n",
       " 'momentum': 0.9,\n",
       " 'n_iter_no_change': 5,\n",
       " 'nesterovs_momentum': True,\n",
       " 'power_t': 0.5,\n",
       " 'random_state': 1,\n",
       " 'shuffle': True,\n",
       " 'solver': 'sgd',\n",
       " 'tol': 0.0001,\n",
       " 'validation_fraction': 0.1,\n",
       " 'verbose': True,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "consistent-neighbor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6.803912316452706,\n",
       " 2.758329302192552,\n",
       " 1.1406935187179963,\n",
       " 0.6718266676867347,\n",
       " 0.47859806853808334,\n",
       " 0.3755889362937117,\n",
       " 0.316648186918025,\n",
       " 0.27807587670992584,\n",
       " 0.2489309894062503,\n",
       " 0.23044114813160171,\n",
       " 0.21331928171444386,\n",
       " 0.20025975401456644,\n",
       " 0.19101363514042174,\n",
       " 0.17818282537399888,\n",
       " 0.16953274732702298,\n",
       " 0.16060558569107083,\n",
       " 0.1549648388579894,\n",
       " 0.14729910841323168,\n",
       " 0.14317719785302332,\n",
       " 0.13708692975635592,\n",
       " 0.13138102332701282,\n",
       " 0.12667361687153184,\n",
       " 0.12255868831361139,\n",
       " 0.11892497416006487,\n",
       " 0.11481052485257455,\n",
       " 0.11079851772406946]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.loss_curve_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "handy-composite",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.25,\n",
       " 0.6180555555555556,\n",
       " 0.6666666666666666,\n",
       " 0.7638888888888888,\n",
       " 0.7916666666666666,\n",
       " 0.8333333333333334,\n",
       " 0.8472222222222222,\n",
       " 0.8680555555555556,\n",
       " 0.8680555555555556,\n",
       " 0.8680555555555556,\n",
       " 0.875,\n",
       " 0.875,\n",
       " 0.875,\n",
       " 0.8819444444444444,\n",
       " 0.8819444444444444,\n",
       " 0.8819444444444444,\n",
       " 0.8819444444444444,\n",
       " 0.8888888888888888,\n",
       " 0.8888888888888888,\n",
       " 0.9097222222222222,\n",
       " 0.8958333333333334,\n",
       " 0.8958333333333334,\n",
       " 0.8958333333333334,\n",
       " 0.8958333333333334,\n",
       " 0.9027777777777778,\n",
       " 0.8958333333333334]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.validation_scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "forward-vegetable",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.25,\n",
       " 0.6180555555555556,\n",
       " 0.6666666666666666,\n",
       " 0.7638888888888888,\n",
       " 0.7916666666666666,\n",
       " 0.8333333333333334,\n",
       " 0.8472222222222222,\n",
       " 0.8680555555555556,\n",
       " 0.8680555555555556,\n",
       " 0.8680555555555556,\n",
       " 0.875,\n",
       " 0.875,\n",
       " 0.875,\n",
       " 0.8819444444444444,\n",
       " 0.8819444444444444,\n",
       " 0.8819444444444444,\n",
       " 0.8819444444444444,\n",
       " 0.8888888888888888,\n",
       " 0.8888888888888888,\n",
       " 0.9097222222222222,\n",
       " 0.8958333333333334,\n",
       " 0.8958333333333334,\n",
       " 0.8958333333333334,\n",
       " 0.8958333333333334,\n",
       " 0.9027777777777778,\n",
       " 0.8958333333333334]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.validation_scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "driven-engineer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.n_iter_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "received-training",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.n_outputs_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "wanted-knife",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-0.0359305 ,  0.09540323, -0.21645666, ..., -0.03721482,\n",
       "          0.08417767, -0.03716144],\n",
       "        [-0.19489927,  0.00884606,  0.06688759, ...,  0.01802465,\n",
       "          0.02659823,  0.14722533],\n",
       "        [-0.1530334 , -0.09419754,  0.009674  , ...,  0.19388996,\n",
       "         -0.09120257, -0.19697041],\n",
       "        ...,\n",
       "        [-0.15380673,  0.11493393, -0.09624781, ..., -0.18045911,\n",
       "         -0.24042749, -0.20120356],\n",
       "        [ 0.07624626,  0.10020553, -0.03007116, ...,  0.05460838,\n",
       "          0.13235346, -0.21882919],\n",
       "        [ 0.08024443,  0.05917963,  0.17948682, ..., -0.17815762,\n",
       "          0.18579488,  0.08591477]]),\n",
       " array([[-8.67694888e-02, -5.25641990e-02,  1.00722774e-02,\n",
       "         -2.40902379e-01,  3.63662305e-02,  6.08338274e-03,\n",
       "          3.10554992e-02,  1.64574736e-01,  6.87368120e-02,\n",
       "         -2.74716234e-02],\n",
       "        [ 6.25969484e-02, -2.26979559e-01,  3.19835602e-01,\n",
       "         -2.00023193e-01, -5.89057229e-02, -1.55804258e-01,\n",
       "          6.03257054e-03,  7.94191749e-03, -7.44384267e-02,\n",
       "          3.26755035e-01],\n",
       "        [ 1.34964802e-01,  1.77525640e-01,  1.10041413e-01,\n",
       "          7.80375758e-02,  2.26400068e-02, -1.90687645e-01,\n",
       "         -5.33264790e-02, -1.40369151e-01, -1.68182709e-01,\n",
       "         -5.32402110e-02],\n",
       "        [-1.62472119e-01, -5.64079712e-02,  2.77891809e-01,\n",
       "          1.33867602e-01, -2.25790250e-01,  1.05650708e-01,\n",
       "         -1.51356636e-01, -3.17301570e-01, -1.82233201e-02,\n",
       "          6.51935104e-02],\n",
       "        [ 2.14441680e-02, -2.46117662e-01,  1.91490094e-01,\n",
       "         -5.43038564e-03,  2.12437764e-01, -1.77895124e-01,\n",
       "         -2.33959435e-01, -1.53956361e-04, -3.16295987e-02,\n",
       "         -2.75961501e-01],\n",
       "        [-2.01250451e-01, -2.10253292e-01, -3.06925536e-01,\n",
       "         -2.10803732e-01,  9.72408589e-02, -7.34525852e-02,\n",
       "          2.64255694e-01, -2.85221794e-01,  2.20248560e-01,\n",
       "          7.86563870e-02],\n",
       "        [ 2.20364811e-01, -2.56235788e-01, -2.15630471e-01,\n",
       "          2.49966558e-01,  5.05835414e-03,  8.64677643e-02,\n",
       "         -2.53188995e-01,  3.08223513e-02,  2.01526862e-01,\n",
       "          2.28336103e-01],\n",
       "        [ 6.99989164e-02, -1.63672850e-01, -1.04367804e-01,\n",
       "         -2.23485033e-01, -8.46291670e-02, -5.77626246e-02,\n",
       "          1.32569530e-01,  5.23947865e-02,  1.07330481e-01,\n",
       "         -8.63130618e-02],\n",
       "        [ 1.07758718e-01,  1.47541837e-01,  8.31546939e-02,\n",
       "         -4.75399630e-02, -2.06853477e-01, -2.67260274e-01,\n",
       "         -7.46675820e-03,  8.99149383e-02, -1.16873365e-01,\n",
       "         -7.46826394e-02],\n",
       "        [-4.02094564e-03,  2.57939440e-01,  2.14740845e-01,\n",
       "          2.12896159e-01,  2.89308465e-01,  1.55293989e-01,\n",
       "         -1.69517636e-01,  1.92319846e-01, -1.90155922e-01,\n",
       "          2.21400490e-01],\n",
       "        [-9.27857344e-02, -1.26848666e-01,  4.39979444e-02,\n",
       "         -2.50778158e-01,  2.31474876e-01, -3.36379971e-02,\n",
       "          1.60203957e-01,  1.23012524e-01,  1.07785041e-01,\n",
       "          1.91439894e-02],\n",
       "        [-1.76217523e-02,  1.06655463e-01,  1.10030215e-01,\n",
       "         -1.48051992e-01,  1.71822522e-01,  2.24704953e-01,\n",
       "          1.60121288e-01,  1.28316388e-01,  1.81440362e-01,\n",
       "         -2.88543392e-01],\n",
       "        [-1.93410982e-01, -8.71389723e-02,  1.17869524e-01,\n",
       "          2.72799981e-01,  1.28366691e-01, -2.60342641e-02,\n",
       "          2.29536357e-01, -8.50244755e-02,  1.06929804e-01,\n",
       "         -2.46055518e-01],\n",
       "        [-1.85824082e-01, -9.68848159e-02, -6.98603026e-02,\n",
       "         -2.02037235e-02,  2.01469059e-01, -1.18370075e-01,\n",
       "         -2.44279772e-01,  1.03508763e-02,  2.35996628e-01,\n",
       "         -6.34784492e-02],\n",
       "        [-9.24381221e-02,  1.41633148e-01,  8.43557738e-02,\n",
       "         -3.08161568e-01,  2.82177496e-01, -2.73694805e-02,\n",
       "         -9.52314629e-02,  5.48421554e-02, -1.10885715e-01,\n",
       "         -1.43510908e-02],\n",
       "        [ 8.98029400e-02, -1.98558607e-01, -1.38948005e-02,\n",
       "          1.31709804e-01,  2.67073543e-01, -2.82090145e-01,\n",
       "          1.94018676e-01,  2.44130479e-01,  2.68499853e-01,\n",
       "          2.40861364e-01],\n",
       "        [-2.01679163e-01,  2.08558629e-01, -1.98801829e-01,\n",
       "         -7.78916969e-02, -8.02265383e-02, -1.24378870e-01,\n",
       "         -8.29697608e-02,  2.26075468e-02, -2.38149242e-01,\n",
       "         -7.06098668e-02],\n",
       "        [ 4.69062530e-02, -2.11720817e-01, -1.46663843e-01,\n",
       "         -1.06373534e-01, -2.45637808e-01,  1.74514566e-01,\n",
       "         -1.36192318e-01, -5.10260147e-02, -5.84397328e-02,\n",
       "         -9.70523595e-02],\n",
       "        [-2.39313884e-01,  1.54604901e-01,  1.68787963e-01,\n",
       "         -6.03505364e-02, -3.16732430e-01, -2.56275112e-01,\n",
       "         -7.95056931e-02, -2.23825839e-01, -1.45017148e-01,\n",
       "         -6.66626674e-02],\n",
       "        [ 2.96280487e-01, -9.79526201e-02,  1.17355727e-01,\n",
       "          3.10339201e-02,  2.38855738e-01, -9.38361834e-02,\n",
       "          1.62612792e-01, -4.75663756e-02,  1.90822909e-01,\n",
       "         -9.28657063e-02],\n",
       "        [ 2.71416063e-01,  1.98124865e-01,  6.17380704e-02,\n",
       "         -2.69998097e-01, -1.79350671e-01, -2.54728137e-01,\n",
       "          1.65788232e-01, -2.34983988e-01,  1.59299537e-01,\n",
       "         -2.66287918e-01],\n",
       "        [-1.55019856e-01, -7.80503766e-02, -3.38221104e-02,\n",
       "          6.61104881e-02,  2.15283951e-01,  1.25817188e-01,\n",
       "         -1.97313883e-01, -2.60129730e-01,  1.26634301e-01,\n",
       "          1.40856746e-02],\n",
       "        [ 4.39592945e-02, -3.54257356e-02,  4.97952974e-02,\n",
       "         -5.14167285e-02, -2.19797316e-02,  4.92067227e-02,\n",
       "         -9.70802766e-03, -2.38408200e-01,  2.51884370e-01,\n",
       "          1.95578567e-01],\n",
       "        [-1.52115443e-02, -4.50435402e-02,  2.39296076e-01,\n",
       "         -4.10522406e-02,  1.72962975e-01, -2.46917896e-01,\n",
       "          1.23433414e-01,  1.22533359e-01, -1.23902541e-01,\n",
       "         -1.11370643e-01],\n",
       "        [ 4.34828219e-02, -3.07857908e-02,  1.91182911e-02,\n",
       "         -2.13977277e-01, -2.73288316e-02, -2.63819078e-01,\n",
       "         -2.69269666e-01,  1.28312237e-01, -2.94610945e-01,\n",
       "          7.02521207e-02],\n",
       "        [ 6.47068205e-02,  9.97647585e-02,  4.36883117e-02,\n",
       "          2.58655754e-01, -6.18601506e-02,  7.42889659e-02,\n",
       "         -6.39119805e-02, -1.80022755e-01, -8.53611513e-02,\n",
       "         -1.07295001e-01],\n",
       "        [-2.70320007e-01, -4.84094357e-02, -1.78329847e-01,\n",
       "          1.56503487e-01, -8.84833055e-02, -7.04142923e-02,\n",
       "         -2.00704690e-01,  1.26878055e-01,  1.47800604e-01,\n",
       "         -1.20173869e-01],\n",
       "        [-2.63648785e-01, -6.80686383e-02,  3.69948819e-02,\n",
       "         -1.46577704e-01,  1.61694962e-01,  2.76297280e-01,\n",
       "         -8.20439524e-02, -1.26939287e-01, -3.01599043e-01,\n",
       "          5.22739996e-02],\n",
       "        [-1.93114441e-01, -2.23594654e-01, -2.57186251e-01,\n",
       "         -1.90458267e-01, -1.91796794e-01, -2.61976624e-01,\n",
       "          2.76729080e-01,  1.09260209e-01, -7.40697671e-02,\n",
       "         -2.57381018e-01],\n",
       "        [-2.57988573e-01,  1.72847068e-01, -4.76331910e-02,\n",
       "         -2.26040687e-01, -1.90743256e-01,  1.11590842e-01,\n",
       "         -4.16140028e-02, -2.29180780e-01, -6.18566246e-02,\n",
       "         -2.59439847e-01],\n",
       "        [-1.39009687e-01, -3.18498062e-02,  1.34238173e-03,\n",
       "          1.55745068e-01, -2.41098842e-01,  1.07948021e-01,\n",
       "         -1.98019476e-01, -1.54322111e-01, -1.00456714e-01,\n",
       "         -2.21972584e-01],\n",
       "        [ 3.28397827e-02, -7.72179095e-02,  2.26585942e-01,\n",
       "          8.60568432e-02, -1.13845990e-01,  4.81776690e-02,\n",
       "         -9.37538230e-02,  6.51299255e-02,  4.02678736e-02,\n",
       "         -1.55932712e-01],\n",
       "        [-9.87783859e-02, -5.22381468e-02,  5.60589169e-02,\n",
       "         -1.36132067e-01,  3.23816021e-02, -1.17788531e-01,\n",
       "          7.03662416e-02, -7.15154640e-02,  1.33514770e-01,\n",
       "          1.62107004e-01],\n",
       "        [ 1.90018197e-01, -2.03769027e-01, -2.19495694e-01,\n",
       "         -4.02604121e-02, -1.67457008e-01, -5.26014939e-02,\n",
       "         -5.31270118e-02, -1.13144901e-01, -1.37755312e-01,\n",
       "         -2.31705550e-01],\n",
       "        [ 1.72453082e-01,  1.11690133e-01, -8.25783033e-02,\n",
       "         -2.69436553e-02,  1.52886296e-01,  9.10309736e-02,\n",
       "         -2.74986228e-01, -1.07728085e-01,  2.39510242e-01,\n",
       "          2.01498464e-01],\n",
       "        [-9.26263997e-02,  1.71926593e-01, -1.12099973e-01,\n",
       "         -1.30438807e-01, -1.12344025e-01, -6.36920280e-02,\n",
       "         -2.88646890e-01,  1.87241940e-02,  1.29371945e-01,\n",
       "          1.11122718e-01],\n",
       "        [ 2.97667745e-03, -6.46391430e-02, -2.27442092e-01,\n",
       "         -1.51438058e-01, -1.98159257e-01,  2.22247146e-01,\n",
       "          2.67330906e-01, -2.99043522e-01, -9.33050301e-02,\n",
       "         -1.12428941e-01],\n",
       "        [ 9.94503350e-02,  7.50177551e-02, -3.65716456e-02,\n",
       "         -1.90173464e-01,  9.15413229e-02, -2.92499012e-01,\n",
       "          2.34758913e-01, -2.09307569e-02, -1.83167036e-01,\n",
       "         -4.18261647e-02],\n",
       "        [-2.16881912e-01, -2.45559375e-01, -1.35793016e-01,\n",
       "          1.55058644e-01,  1.61190561e-01,  8.48045560e-02,\n",
       "         -9.97890860e-02,  2.62512925e-02,  1.26499195e-01,\n",
       "         -1.85238459e-01],\n",
       "        [ 1.39571362e-01,  1.74464405e-01,  8.37336429e-02,\n",
       "         -1.80533024e-01, -1.70710321e-01,  2.01643987e-02,\n",
       "         -2.23211868e-01,  2.10856119e-01, -4.35311072e-02,\n",
       "         -7.07044106e-02],\n",
       "        [ 4.04409200e-02, -1.50255403e-01,  7.74396464e-02,\n",
       "         -1.46053821e-01, -1.58164900e-01, -1.78014843e-04,\n",
       "          1.87848710e-01,  6.47971882e-02, -2.21432270e-01,\n",
       "         -2.11907127e-01],\n",
       "        [-6.65829510e-02, -6.17384836e-02,  2.05532758e-01,\n",
       "          2.24718991e-01, -2.70568111e-01, -1.80592440e-01,\n",
       "         -7.18813303e-02, -1.78979544e-01,  2.32642153e-01,\n",
       "         -1.70981171e-01],\n",
       "        [ 1.29536537e-01,  2.32373164e-01, -2.48372201e-02,\n",
       "          1.33112481e-01,  1.23056432e-01,  1.25606466e-01,\n",
       "          1.18872026e-01,  3.10695824e-01, -1.32408751e-01,\n",
       "          1.50889337e-01],\n",
       "        [ 2.44150184e-01,  1.47858841e-01,  1.84391608e-01,\n",
       "          2.19512356e-01, -1.36335649e-01,  1.92307323e-03,\n",
       "         -1.70372756e-01,  1.88682819e-01, -9.73085538e-02,\n",
       "          2.47899738e-01],\n",
       "        [-1.70114426e-01, -8.38698107e-02,  1.05595148e-01,\n",
       "          2.45734228e-01,  1.10170438e-01, -8.90440171e-02,\n",
       "         -2.57518973e-01, -9.80571574e-02, -2.01142281e-02,\n",
       "          1.27968745e-01],\n",
       "        [ 2.14948479e-01, -3.18370363e-01, -2.07569256e-01,\n",
       "         -1.13398859e-01,  5.58410125e-02,  2.56038465e-02,\n",
       "         -3.88149840e-02,  2.27314528e-01,  8.24452171e-02,\n",
       "         -2.11561411e-01],\n",
       "        [-1.54647522e-01, -2.33974008e-02, -3.00982898e-02,\n",
       "          1.44791410e-01, -8.07507626e-02,  1.14377400e-01,\n",
       "         -1.59751173e-01, -1.33792716e-03,  3.01915916e-01,\n",
       "         -1.69585129e-01],\n",
       "        [-1.14096111e-01, -1.81274285e-01,  2.68631833e-01,\n",
       "         -3.82124504e-02,  1.91082135e-01,  2.00001921e-01,\n",
       "         -2.18681891e-01, -1.05035791e-01,  2.52527821e-02,\n",
       "          2.60991674e-01],\n",
       "        [ 2.74851861e-01, -9.38673340e-02,  1.53785653e-01,\n",
       "          1.91761950e-01, -1.34764937e-01, -1.48621062e-01,\n",
       "          7.98056640e-02,  4.11274151e-02, -2.15696541e-01,\n",
       "          1.63214323e-01],\n",
       "        [-9.36233310e-02,  1.19586055e-01, -2.69712123e-01,\n",
       "          2.29539386e-02,  1.87984389e-01, -1.00623592e-01,\n",
       "          1.27123007e-01, -6.15968480e-02, -6.55397523e-02,\n",
       "         -1.22979087e-01],\n",
       "        [ 1.35443338e-01,  2.39356014e-01, -1.18048991e-02,\n",
       "          2.62944868e-01,  1.69157297e-01, -1.18843546e-01,\n",
       "         -1.59910268e-01, -7.94544328e-02, -3.43721476e-02,\n",
       "         -8.67582843e-03],\n",
       "        [ 1.63993622e-01,  1.62525444e-01, -2.51120785e-01,\n",
       "         -6.64279221e-03, -1.01475330e-01,  6.65373598e-03,\n",
       "          4.91250582e-02,  1.80283761e-01, -9.35821958e-02,\n",
       "          2.82640956e-01],\n",
       "        [-1.46904331e-01,  1.21619520e-02,  9.87857203e-02,\n",
       "          2.20982695e-01,  1.55356091e-01,  2.63114261e-01,\n",
       "          2.53716205e-02,  2.10334095e-01,  1.37154094e-01,\n",
       "         -1.69931874e-01],\n",
       "        [-2.63004518e-01,  1.78609232e-01,  9.37438396e-02,\n",
       "         -1.23888206e-01, -2.26028510e-01,  1.03404321e-01,\n",
       "          1.26523528e-01,  3.07013807e-02,  9.41590978e-02,\n",
       "         -5.41505708e-02],\n",
       "        [ 2.08733583e-01,  2.62947151e-02,  2.25693016e-01,\n",
       "          1.31114178e-01,  1.25870137e-02,  1.20993212e-01,\n",
       "          2.15192574e-01, -1.74332878e-01, -3.27568408e-02,\n",
       "          2.03874798e-01],\n",
       "        [-2.49245150e-01, -2.14946937e-01, -5.73467384e-02,\n",
       "         -2.11748636e-01,  1.22365484e-01,  2.52412559e-01,\n",
       "          2.85378527e-02,  2.22740089e-01, -1.93134246e-01,\n",
       "          1.11175730e-01],\n",
       "        [ 2.83358017e-02,  1.91753645e-01, -3.62049460e-04,\n",
       "          2.32320849e-01, -4.68838311e-03,  2.45958335e-01,\n",
       "          2.47029738e-01, -4.83082151e-02, -1.94710414e-02,\n",
       "         -2.71907266e-01],\n",
       "        [ 6.24282394e-02, -1.45717892e-01, -7.24455597e-02,\n",
       "         -1.30446625e-01, -1.08262565e-02,  1.56520749e-02,\n",
       "          7.96021018e-02,  1.00800899e-01,  1.96473079e-01,\n",
       "          4.04831056e-02],\n",
       "        [-3.27429989e-02, -5.71248005e-02, -2.44579939e-01,\n",
       "         -1.98793564e-02, -5.69555392e-02, -1.70755512e-01,\n",
       "          1.71825148e-01,  1.11329493e-01,  2.73012653e-01,\n",
       "         -6.19302560e-02],\n",
       "        [-6.84414413e-02,  7.63577451e-02, -7.23015442e-02,\n",
       "          3.23030964e-02,  2.31361383e-01,  6.44620103e-02,\n",
       "         -1.38490681e-01,  1.04038718e-01,  2.40451933e-01,\n",
       "          1.31948643e-01],\n",
       "        [-1.04398401e-01,  6.33168599e-02,  8.59324429e-02,\n",
       "         -2.12802593e-01,  2.37962894e-01, -7.52119375e-02,\n",
       "          1.07174801e-01,  2.44018427e-01,  9.92125528e-02,\n",
       "          2.49091671e-01],\n",
       "        [ 9.67580262e-02, -1.67811144e-01,  9.93477487e-02,\n",
       "         -1.13700109e-02, -1.15724374e-01,  1.29492745e-01,\n",
       "          1.40531668e-01,  2.51149770e-01, -1.56997872e-01,\n",
       "          6.44525385e-02],\n",
       "        [ 1.35068583e-01, -6.26917316e-02, -1.74479994e-01,\n",
       "          2.92983952e-01,  1.26393956e-01,  6.39332137e-02,\n",
       "          4.21309050e-03,  2.85797948e-01,  2.18829509e-01,\n",
       "          3.00909128e-01],\n",
       "        [-3.12795818e-02,  1.48380395e-01, -1.47693311e-01,\n",
       "          3.14058134e-02, -6.24702489e-02, -2.21729440e-01,\n",
       "         -2.04649324e-01,  2.68335923e-01, -1.97021640e-01,\n",
       "          8.43408251e-02]])]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.coefs_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "speaking-hurricane",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33618"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.t_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "outside-humor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "american-harvard",
   "metadata": {},
   "outputs": [],
   "source": [
    "ee = mlp.predict_proba(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "related-cursor",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1437\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "print(len(ee))\n",
    "print(len(ee[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "dated-departure",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy(y, y_hat):\n",
    "    res = 0\n",
    "    ave = 0\n",
    "    for ele in range(len(y_hat)):\n",
    "        for i in range(10):\n",
    "            if y[ele] == i:\n",
    "                res = res - math.log(y_hat[ele][i])\n",
    "        ave = ave+res\n",
    "    return ave/len(y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "touched-handling",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109.10545048193376\n"
     ]
    }
   ],
   "source": [
    "print(cross_entropy(y_train, ee))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "settled-worth",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "tender-triumph",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 7.29500874\n",
      "Validation score: 0.191304\n",
      "Iteration 2, loss = 3.35274142\n",
      "Validation score: 0.452174\n",
      "Iteration 3, loss = 1.49494619\n",
      "Validation score: 0.686957\n",
      "Iteration 4, loss = 0.85355347\n",
      "Validation score: 0.756522\n",
      "Iteration 5, loss = 0.61631590\n",
      "Validation score: 0.817391\n",
      "Iteration 6, loss = 0.47698253\n",
      "Validation score: 0.852174\n",
      "Iteration 7, loss = 0.39922797\n",
      "Validation score: 0.834783\n",
      "Iteration 8, loss = 0.34103847\n",
      "Validation score: 0.860870\n",
      "Iteration 9, loss = 0.30209043\n",
      "Validation score: 0.860870\n",
      "Iteration 10, loss = 0.26893853\n",
      "Validation score: 0.878261\n",
      "Iteration 11, loss = 0.24539159\n",
      "Validation score: 0.895652\n",
      "Iteration 12, loss = 0.22810032\n",
      "Validation score: 0.913043\n",
      "Iteration 13, loss = 0.21321170\n",
      "Validation score: 0.895652\n",
      "Iteration 14, loss = 0.20050440\n",
      "Validation score: 0.895652\n",
      "Iteration 15, loss = 0.18835045\n",
      "Validation score: 0.904348\n",
      "Iteration 16, loss = 0.17911145\n",
      "Validation score: 0.886957\n",
      "Iteration 17, loss = 0.17061472\n",
      "Validation score: 0.886957\n",
      "Iteration 18, loss = 0.16327586\n",
      "Validation score: 0.886957\n",
      "Validation score did not improve more than tol=0.000100 for 5 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 7.29500874\n",
      "Validation score: 0.191304\n",
      "Iteration 2, loss = 3.35274142\n",
      "Validation score: 0.452174\n",
      "Iteration 3, loss = 1.49494619\n",
      "Validation score: 0.686957\n",
      "Iteration 4, loss = 0.85355347\n",
      "Validation score: 0.756522\n",
      "Iteration 5, loss = 0.61631590\n",
      "Validation score: 0.817391\n",
      "Iteration 6, loss = 0.47698253\n",
      "Validation score: 0.852174\n",
      "Iteration 7, loss = 0.39922797\n",
      "Validation score: 0.834783\n",
      "Iteration 8, loss = 0.34103847\n",
      "Validation score: 0.860870\n",
      "Iteration 9, loss = 0.30209043\n",
      "Validation score: 0.860870\n",
      "Iteration 10, loss = 0.26893853\n",
      "Validation score: 0.878261\n",
      "Iteration 11, loss = 0.24539159\n",
      "Validation score: 0.895652\n",
      "Iteration 12, loss = 0.22810032\n",
      "Validation score: 0.913043\n",
      "Iteration 13, loss = 0.21321170\n",
      "Validation score: 0.895652\n",
      "Iteration 14, loss = 0.20050440\n",
      "Validation score: 0.895652\n",
      "Iteration 15, loss = 0.18835045\n",
      "Validation score: 0.904348\n",
      "Iteration 16, loss = 0.17911145\n",
      "Validation score: 0.886957\n",
      "Iteration 17, loss = 0.17061472\n",
      "Validation score: 0.886957\n",
      "Iteration 18, loss = 0.16327586\n",
      "Validation score: 0.886957\n",
      "Validation score did not improve more than tol=0.000100 for 5 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 7.29500874\n",
      "Validation score: 0.191304\n",
      "Iteration 2, loss = 3.35274142\n",
      "Validation score: 0.452174\n",
      "Iteration 3, loss = 1.49494619\n",
      "Validation score: 0.686957\n",
      "Iteration 4, loss = 0.85355347\n",
      "Validation score: 0.756522\n",
      "Iteration 5, loss = 0.61631590\n",
      "Validation score: 0.817391\n",
      "Iteration 6, loss = 0.47698253\n",
      "Validation score: 0.852174\n",
      "Iteration 7, loss = 0.39922797\n",
      "Validation score: 0.834783\n",
      "Iteration 8, loss = 0.34103847\n",
      "Validation score: 0.860870\n",
      "Iteration 9, loss = 0.30209043\n",
      "Validation score: 0.860870\n",
      "Iteration 10, loss = 0.26893853\n",
      "Validation score: 0.878261\n",
      "Iteration 11, loss = 0.24539159\n",
      "Validation score: 0.895652\n",
      "Iteration 12, loss = 0.22810032\n",
      "Validation score: 0.913043\n",
      "Iteration 13, loss = 0.21321170\n",
      "Validation score: 0.895652\n",
      "Iteration 14, loss = 0.20050440\n",
      "Validation score: 0.895652\n",
      "Iteration 15, loss = 0.18835045\n",
      "Validation score: 0.904348\n",
      "Iteration 16, loss = 0.17911145\n",
      "Validation score: 0.886957\n",
      "Iteration 17, loss = 0.17061472\n",
      "Validation score: 0.886957\n",
      "Iteration 18, loss = 0.16327586\n",
      "Validation score: 0.886957\n",
      "Validation score did not improve more than tol=0.000100 for 5 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 7.29500874\n",
      "Validation score: 0.191304\n",
      "Iteration 2, loss = 3.35274142\n",
      "Validation score: 0.452174\n",
      "Iteration 3, loss = 1.49494619\n",
      "Validation score: 0.686957\n",
      "Iteration 4, loss = 0.85355347\n",
      "Validation score: 0.756522\n",
      "Iteration 5, loss = 0.61631590\n",
      "Validation score: 0.817391\n",
      "Iteration 6, loss = 0.47698253\n",
      "Validation score: 0.852174\n",
      "Iteration 7, loss = 0.39922797\n",
      "Validation score: 0.834783\n",
      "Iteration 8, loss = 0.34103847\n",
      "Validation score: 0.860870\n",
      "Iteration 9, loss = 0.30209043\n",
      "Validation score: 0.860870\n",
      "Iteration 10, loss = 0.26893853\n",
      "Validation score: 0.878261\n",
      "Iteration 11, loss = 0.24539159\n",
      "Validation score: 0.895652\n",
      "Iteration 12, loss = 0.22810032\n",
      "Validation score: 0.913043\n",
      "Iteration 13, loss = 0.21321170\n",
      "Validation score: 0.895652\n",
      "Iteration 14, loss = 0.20050440\n",
      "Validation score: 0.895652\n",
      "Iteration 15, loss = 0.18835045\n",
      "Validation score: 0.904348\n",
      "Iteration 16, loss = 0.17911145\n",
      "Validation score: 0.886957\n",
      "Iteration 17, loss = 0.17061472\n",
      "Validation score: 0.886957\n",
      "Iteration 18, loss = 0.16327586\n",
      "Validation score: 0.886957\n",
      "Validation score did not improve more than tol=0.000100 for 5 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 7.29500874\n",
      "Validation score: 0.191304\n",
      "Iteration 2, loss = 3.35274142\n",
      "Validation score: 0.452174\n",
      "Iteration 3, loss = 1.49494619\n",
      "Validation score: 0.686957\n",
      "Iteration 4, loss = 0.85355347\n",
      "Validation score: 0.756522\n",
      "Iteration 5, loss = 0.61631590\n",
      "Validation score: 0.817391\n",
      "Iteration 6, loss = 0.47698253\n",
      "Validation score: 0.852174\n",
      "Iteration 7, loss = 0.39922797\n",
      "Validation score: 0.834783\n",
      "Iteration 8, loss = 0.34103847\n",
      "Validation score: 0.860870\n",
      "Iteration 9, loss = 0.30209043\n",
      "Validation score: 0.860870\n",
      "Iteration 10, loss = 0.26893853\n",
      "Validation score: 0.878261\n",
      "Iteration 11, loss = 0.24539159\n",
      "Validation score: 0.895652\n",
      "Iteration 12, loss = 0.22810032\n",
      "Validation score: 0.913043\n",
      "Iteration 13, loss = 0.21321170\n",
      "Validation score: 0.895652\n",
      "Iteration 14, loss = 0.20050440\n",
      "Validation score: 0.895652\n",
      "Iteration 15, loss = 0.18835045\n",
      "Validation score: 0.904348\n",
      "Iteration 16, loss = 0.17911145\n",
      "Validation score: 0.886957\n",
      "Iteration 17, loss = 0.17061472\n",
      "Validation score: 0.886957\n",
      "Iteration 18, loss = 0.16327586\n",
      "Validation score: 0.886957\n",
      "Validation score did not improve more than tol=0.000100 for 5 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 7.29500874\n",
      "Validation score: 0.191304\n",
      "Iteration 2, loss = 3.35274142\n",
      "Validation score: 0.452174\n",
      "Iteration 3, loss = 1.49494619\n",
      "Validation score: 0.686957\n",
      "Iteration 4, loss = 0.85355347\n",
      "Validation score: 0.756522\n",
      "Iteration 5, loss = 0.61631590\n",
      "Validation score: 0.817391\n",
      "Iteration 6, loss = 0.47698253\n",
      "Validation score: 0.852174\n",
      "Iteration 7, loss = 0.39922797\n",
      "Validation score: 0.834783\n",
      "Iteration 8, loss = 0.34103847\n",
      "Validation score: 0.860870\n",
      "Iteration 9, loss = 0.30209043\n",
      "Validation score: 0.860870\n",
      "Iteration 10, loss = 0.26893853\n",
      "Validation score: 0.878261\n",
      "Iteration 11, loss = 0.24539159\n",
      "Validation score: 0.895652\n",
      "Iteration 12, loss = 0.22810032\n",
      "Validation score: 0.913043\n",
      "Iteration 13, loss = 0.21321170\n",
      "Validation score: 0.895652\n",
      "Iteration 14, loss = 0.20050440\n",
      "Validation score: 0.895652\n",
      "Iteration 15, loss = 0.18835045\n",
      "Validation score: 0.904348\n",
      "Iteration 16, loss = 0.17911145\n",
      "Validation score: 0.886957\n",
      "Iteration 17, loss = 0.17061472\n",
      "Validation score: 0.886957\n",
      "Iteration 18, loss = 0.16327586\n",
      "Validation score: 0.886957\n",
      "Validation score did not improve more than tol=0.000100 for 5 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 7.29500874\n",
      "Validation score: 0.191304\n",
      "Iteration 2, loss = 3.35274142\n",
      "Validation score: 0.452174\n",
      "Iteration 3, loss = 1.49494619\n",
      "Validation score: 0.686957\n",
      "Iteration 4, loss = 0.85355347\n",
      "Validation score: 0.756522\n",
      "Iteration 5, loss = 0.61631590\n",
      "Validation score: 0.817391\n",
      "Iteration 6, loss = 0.47698253\n",
      "Validation score: 0.852174\n",
      "Iteration 7, loss = 0.39922797\n",
      "Validation score: 0.834783\n",
      "Iteration 8, loss = 0.34103847\n",
      "Validation score: 0.860870\n",
      "Iteration 9, loss = 0.30209043\n",
      "Validation score: 0.860870\n",
      "Iteration 10, loss = 0.26893853\n",
      "Validation score: 0.878261\n",
      "Iteration 11, loss = 0.24539159\n",
      "Validation score: 0.895652\n",
      "Iteration 12, loss = 0.22810032\n",
      "Validation score: 0.913043\n",
      "Iteration 13, loss = 0.21321170\n",
      "Validation score: 0.895652\n",
      "Iteration 14, loss = 0.20050440\n",
      "Validation score: 0.895652\n",
      "Iteration 15, loss = 0.18835045\n",
      "Validation score: 0.904348\n",
      "Iteration 16, loss = 0.17911145\n",
      "Validation score: 0.886957\n",
      "Iteration 17, loss = 0.17061472\n",
      "Validation score: 0.886957\n",
      "Iteration 18, loss = 0.16327586\n",
      "Validation score: 0.886957\n",
      "Validation score did not improve more than tol=0.000100 for 5 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 7.29500874\n",
      "Validation score: 0.191304\n",
      "Iteration 2, loss = 3.35274142\n",
      "Validation score: 0.452174\n",
      "Iteration 3, loss = 1.49494619\n",
      "Validation score: 0.686957\n",
      "Iteration 4, loss = 0.85355347\n",
      "Validation score: 0.756522\n",
      "Iteration 5, loss = 0.61631590\n",
      "Validation score: 0.817391\n",
      "Iteration 6, loss = 0.47698253\n",
      "Validation score: 0.852174\n",
      "Iteration 7, loss = 0.39922797\n",
      "Validation score: 0.834783\n",
      "Iteration 8, loss = 0.34103847\n",
      "Validation score: 0.860870\n",
      "Iteration 9, loss = 0.30209043\n",
      "Validation score: 0.860870\n",
      "Iteration 10, loss = 0.26893853\n",
      "Validation score: 0.878261\n",
      "Iteration 11, loss = 0.24539159\n",
      "Validation score: 0.895652\n",
      "Iteration 12, loss = 0.22810032\n",
      "Validation score: 0.913043\n",
      "Iteration 13, loss = 0.21321170\n",
      "Validation score: 0.895652\n",
      "Iteration 14, loss = 0.20050440\n",
      "Validation score: 0.895652\n",
      "Iteration 15, loss = 0.18835045\n",
      "Validation score: 0.904348\n",
      "Iteration 16, loss = 0.17911145\n",
      "Validation score: 0.886957\n",
      "Iteration 17, loss = 0.17061472\n",
      "Validation score: 0.886957\n",
      "Iteration 18, loss = 0.16327586\n",
      "Validation score: 0.886957\n",
      "Validation score did not improve more than tol=0.000100 for 5 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 7.29500874\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation score: 0.191304\n",
      "Iteration 2, loss = 3.35274142\n",
      "Validation score: 0.452174\n",
      "Iteration 3, loss = 1.49494619\n",
      "Validation score: 0.686957\n",
      "Iteration 4, loss = 0.85355347\n",
      "Validation score: 0.756522\n",
      "Iteration 5, loss = 0.61631590\n",
      "Validation score: 0.817391\n",
      "Iteration 6, loss = 0.47698253\n",
      "Validation score: 0.852174\n",
      "Iteration 7, loss = 0.39922797\n",
      "Validation score: 0.834783\n",
      "Iteration 8, loss = 0.34103847\n",
      "Validation score: 0.860870\n",
      "Iteration 9, loss = 0.30209043\n",
      "Validation score: 0.860870\n",
      "Iteration 10, loss = 0.26893853\n",
      "Validation score: 0.878261\n",
      "Iteration 11, loss = 0.24539159\n",
      "Validation score: 0.895652\n",
      "Iteration 12, loss = 0.22810032\n",
      "Validation score: 0.913043\n",
      "Iteration 13, loss = 0.21321170\n",
      "Validation score: 0.895652\n",
      "Iteration 14, loss = 0.20050440\n",
      "Validation score: 0.895652\n",
      "Iteration 15, loss = 0.18835045\n",
      "Validation score: 0.904348\n",
      "Iteration 16, loss = 0.17911145\n",
      "Validation score: 0.886957\n",
      "Iteration 17, loss = 0.17061472\n",
      "Validation score: 0.886957\n",
      "Iteration 18, loss = 0.16327586\n",
      "Validation score: 0.886957\n",
      "Validation score did not improve more than tol=0.000100 for 5 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 7.29500874\n",
      "Validation score: 0.191304\n",
      "Iteration 2, loss = 3.35274142\n",
      "Validation score: 0.452174\n",
      "Iteration 3, loss = 1.49494619\n",
      "Validation score: 0.686957\n",
      "Iteration 4, loss = 0.85355347\n",
      "Validation score: 0.756522\n",
      "Iteration 5, loss = 0.61631590\n",
      "Validation score: 0.817391\n",
      "Iteration 6, loss = 0.47698253\n",
      "Validation score: 0.852174\n",
      "Iteration 7, loss = 0.39922797\n",
      "Validation score: 0.834783\n",
      "Iteration 8, loss = 0.34103847\n",
      "Validation score: 0.860870\n",
      "Iteration 9, loss = 0.30209043\n",
      "Validation score: 0.860870\n",
      "Iteration 10, loss = 0.26893853\n",
      "Validation score: 0.878261\n",
      "Iteration 11, loss = 0.24539159\n",
      "Validation score: 0.895652\n",
      "Iteration 12, loss = 0.22810032\n",
      "Validation score: 0.913043\n",
      "Iteration 13, loss = 0.21321170\n",
      "Validation score: 0.895652\n",
      "Iteration 14, loss = 0.20050440\n",
      "Validation score: 0.895652\n",
      "Iteration 15, loss = 0.18835045\n",
      "Validation score: 0.904348\n",
      "Iteration 16, loss = 0.17911145\n",
      "Validation score: 0.886957\n",
      "Iteration 17, loss = 0.17061472\n",
      "Validation score: 0.886957\n",
      "Iteration 18, loss = 0.16327586\n",
      "Validation score: 0.886957\n",
      "Validation score did not improve more than tol=0.000100 for 5 consecutive epochs. Stopping.\n"
     ]
    }
   ],
   "source": [
    "N_TRAIN_SAMPLES = X_train.shape[0]\n",
    "N_EPOCHS = 10\n",
    "N_CLASSES = np.unique(y_train)\n",
    "\n",
    "scores_train = []\n",
    "scores_val = []\n",
    "loss_val = []\n",
    "loss_train = []\n",
    "\n",
    "\n",
    "# EPOCH\n",
    "epoch = 0\n",
    "while epoch < N_EPOCHS:\n",
    "    # SHUFFLING\n",
    "    random_perm = np.random.permutation(X_train.shape[0])\n",
    "    xx_train, xx_test, yy_train, yy_test = model_selection.train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "    mlp.fit(xx_train, yy_train)\n",
    "    prob_train = mlp.predict_proba(xx_train)\n",
    "    prob_test = mlp.predict_proba(xx_test)\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "    # SCORE TRAIN\n",
    "    scores_train.append(mlp.score(xx_train, yy_train))\n",
    "    scores_val.append(mlp.score(xx_test, yy_test))\n",
    "    loss_val.append(cross_entropy(yy_test, prob_test))\n",
    "    loss_train.append(cross_entropy(yy_train, prob_train))\n",
    "\n",
    "    epoch += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "computational-massachusetts",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9347258485639687,\n",
       " 0.9347258485639687,\n",
       " 0.9347258485639687,\n",
       " 0.9347258485639687,\n",
       " 0.9347258485639687,\n",
       " 0.9347258485639687,\n",
       " 0.9347258485639687,\n",
       " 0.9347258485639687,\n",
       " 0.9347258485639687,\n",
       " 0.9347258485639687]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "naval-money",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1 of 18: Validation Loss =  7.29500874414976 Validation score =  0.19130434782608696 Eta = 0.001\n",
      "Epoch  2 of 18: Validation Loss =  3.352741419973616 Validation score =  0.45217391304347826 Eta = 0.001\n",
      "Epoch  3 of 18: Validation Loss =  1.4949461866217486 Validation score =  0.6869565217391305 Eta = 0.001\n",
      "Epoch  4 of 18: Validation Loss =  0.8535534700224807 Validation score =  0.7565217391304347 Eta = 0.001\n",
      "Epoch  5 of 18: Validation Loss =  0.616315895154119 Validation score =  0.8173913043478261 Eta = 0.001\n",
      "Epoch  6 of 18: Validation Loss =  0.4769825319094993 Validation score =  0.8521739130434782 Eta = 0.001\n",
      "Epoch  7 of 18: Validation Loss =  0.39922797404826843 Validation score =  0.8347826086956521 Eta = 0.001\n",
      "Epoch  8 of 18: Validation Loss =  0.3410384657812385 Validation score =  0.8608695652173913 Eta = 0.001\n",
      "Epoch  9 of 18: Validation Loss =  0.3020904267778269 Validation score =  0.8608695652173913 Eta = 0.001\n",
      "Epoch  10 of 18: Validation Loss =  0.2689385309441057 Validation score =  0.8782608695652174 Eta = 0.001\n",
      "Epoch  11 of 18: Validation Loss =  0.24539158580155218 Validation score =  0.8956521739130435 Eta = 0.001\n",
      "Epoch  12 of 18: Validation Loss =  0.22810031746827195 Validation score =  0.9130434782608695 Eta = 0.001\n",
      "Epoch  13 of 18: Validation Loss =  0.21321170358029312 Validation score =  0.8956521739130435 Eta = 0.001\n",
      "Epoch  14 of 18: Validation Loss =  0.20050440480463572 Validation score =  0.8956521739130435 Eta = 0.001\n",
      "Epoch  15 of 18: Validation Loss =  0.1883504506316119 Validation score =  0.9043478260869565 Eta = 0.001\n",
      "Epoch  16 of 18: Validation Loss =  0.1791114529620948 Validation score =  0.8869565217391304 Eta = 0.001\n",
      "Epoch  17 of 18: Validation Loss =  0.17061472162029132 Validation score =  0.8869565217391304 Eta = 0.001\n",
      "Epoch  18 of 18: Validation Loss =  0.16327586141207154 Validation score =  0.8869565217391304 Eta = 0.001\n"
     ]
    }
   ],
   "source": [
    "for epo in range(mlp.n_iter_):\n",
    "    print(\"Epoch \", epo+1, \"of 18: Validation Loss = \", mlp.loss_curve_[epo], \"Validation score = \",mlp.validation_scores_[epo], \"Eta = 0.001\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "responsible-harrison",
   "metadata": {},
   "source": [
    "##### b) Two graphs \n",
    "First graph plots both training loss and validation loss against epochs.  \n",
    "Second graph plots validation score vs epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "entire-composition",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(mlp.validation_scores_, color='green', alpha=0.8, label='score')\n",
    "plt.plot(mlp.loss_curve_, color='magenta', alpha=0.8, label='loss')\n",
    "plt.title(\"Evaluation over epochs\", fontsize=14)\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "clear-option",
   "metadata": {},
   "source": [
    "##### c)For training data: accuracy, no. of correct predictions, confusion matrix, precision, recall, f1 score for each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "suspended-group",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "trying-spokesman",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = mlp.predict(X_train)\n",
    "y_pred_prob = mlp.predict_proba(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "together-memorial",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[1288    4]\n",
      "  [   2  143]]\n",
      "\n",
      " [[1271   12]\n",
      "  [  16  138]]\n",
      "\n",
      " [[1284    9]\n",
      "  [  10  134]]\n",
      "\n",
      " [[1275   13]\n",
      "  [  16  133]]\n",
      "\n",
      " [[1293    9]\n",
      "  [  13  122]]\n",
      "\n",
      " [[1294    8]\n",
      "  [   8  127]]\n",
      "\n",
      " [[1288    3]\n",
      "  [   7  139]]\n",
      "\n",
      " [[1285    7]\n",
      "  [   8  137]]\n",
      "\n",
      " [[1268   25]\n",
      "  [  15  129]]\n",
      "\n",
      " [[1278   19]\n",
      "  [  14  126]]]\n"
     ]
    }
   ],
   "source": [
    "mat = multilabel_confusion_matrix(y_train, y_pred)\n",
    "print(mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "restricted-cover",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9241475295755045"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "infectious-clothing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9241475295755045"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(y_train, y_pred, average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "frozen-methodology",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9241475295755045"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_train, y_pred, average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "stable-database",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9241475295755045"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_train, y_pred, average='micro')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stopped-museum",
   "metadata": {},
   "source": [
    "##### d) For test data: accuracy, no. of correct predictions, confusion matrix, precision, recall, f1 score for each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "novel-syndication",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = mlp.predict(X_test)\n",
    "y_pred_prob_test = mlp.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "solid-stocks",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[326   1]\n",
      "  [  2  31]]\n",
      "\n",
      " [[328   4]\n",
      "  [  4  24]]\n",
      "\n",
      " [[324   3]\n",
      "  [  3  30]]\n",
      "\n",
      " [[324   2]\n",
      "  [  1  33]]\n",
      "\n",
      " [[312   2]\n",
      "  [  3  43]]\n",
      "\n",
      " [[310   3]\n",
      "  [  5  42]]\n",
      "\n",
      " [[325   0]\n",
      "  [  1  34]]\n",
      "\n",
      " [[324   2]\n",
      "  [  3  31]]\n",
      "\n",
      " [[323   7]\n",
      "  [  5  25]]\n",
      "\n",
      " [[311   9]\n",
      "  [  6  34]]]\n"
     ]
    }
   ],
   "source": [
    "mat = multilabel_confusion_matrix(y_test, y_pred_test)\n",
    "print(mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "herbal-station",
   "metadata": {},
   "source": [
    "**The right prediction: sum of the value on the diagonal(from left to right)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "banner-operation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9083333333333333"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "absent-surrey",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9083333333333333"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(y_test, y_pred_test, average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "smaller-packing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9083333333333333"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_test, y_pred_test, average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "mounted-detection",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9083333333333333"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, y_pred_test, average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "concerned-jimmy",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "absolute-exclusive",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unable-bouquet",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "instant-documentation",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "athletic-fellow",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
